<br>
<br>
<br>
<br>
<br>
# Reading
<br>
<br>
<br>
<br>
<br>
### Week 01
#### “Programming Design Systems” by Rune Madsen
##### "There is no reason for the design process to end with the birth of a product"
I personally like this statement and agree with it. There is always possiblities for the design to iterate or evolve because of various reasons, so as to adapt to new context, needs, users etc.
##### "Code allows designers to not just create designs, but build digital systems that create designs."
This reminds me a discussion that if digital tools, such as code here, would kill the creativity of designers and arts. For me, I agree that digital tools does make the design outcome more predictable. I also personally appreciate the handdrawing works, which always bring me more surprise. However, I do not think that being more predictable means less creativity. Code is a tool just like the pencil at the hand of designer. Creative or not still depends on the designer. Moreover, with an alternative way or tool for us to create design, I believe that there would be more possibilities and creativity.
<br>
<br>
<br>
<br>
<br>
### Week 02
#### "You look like a thing and I love you" by Janelle Shane
##### "The tench AI’s finger-finding trick would help it identify trophy fish in human hands, but it was going to be ill prepared when looking for the fish in the wild."
This is so interesting. I am very curious what would happen if the tench AI was trained by images taken in the wild, rather than trophy fish in human hands, at the first. Would it still be ill prepared? In turn, is it able to recognize a trophy fish not in the wild, such as in human hands? I feel the "brain" of AI actually is quite different with ours, which means we learn and think differently. Therefore, it might be unreasonable to regard it as "intelligence" and simply trained it in the way which is effective for human.
##### "The common thread seems to be that if data comes from humans, it will likely have bias in it."
##### "Since humans tend to be biased, the algorithms that learn from them will also tend to be biased unless humans take extra care to find and remove the bias."
If so, it seems that it is never possible to remove the data bias. As long as there are differences, there would be bias. But differences in data are objective while bias are subjective. Instead of pursuing remove bias, how about to look at data differences from an objective and scientific perspective?
##### "People treat these kinds of algorithms as if they are making recommendations, but it’s a lot more accurate to say that they’re making predictions. They’re not telling us what the best decision would be—they’re just learning to predict human behavior."
This is kind of suprising for me but I am glad to learn it. It is so easy for people like me to misundertood AI, regarding it as super smart, at least smarter than human. But actually the ability to computate large amounts of datasets does not guarantee "intelligence".
<br>
<br>
<br>
<br>
<br>
### Week 03
#### "Notes on Failure" by Joyce Carol Oates & AI Ethics Case Studies
##### "the genius cannot know that he is a genius - not really: he has hopes, he has premonitions, he suffers raging paranoid doubts, but he can have, in the end, only himself for measurement."
It reads poetic. For me, I think it is not just about the genius, but also everyone. Everyone has moments of doubt or self-doubt. We will feel failure at these moments. If we take the emotion out of it, describing “failure” more objectively, it is more of our cognition of the current position: a position that is some distance from an ideal goal. It is not negative or positive, just an objective situation. But it is nice to realize our situation, which makes us to reflect and look for the reasons, alternative paths, new goals that lead/block us towards the ideal destination. Then we can take actions based on it and progress. As long as we doubt, or have higher goals, we will put ourselves in such a position, which is not failure, just a destination has not yet arrived.
##### "Charlie is projecting values and life choices that they, themselves, may not necessarily endorse."
##### "Can and should Charlie’s ends and means be made transparent to individual users? In your response, consider both the narrower and the richer definitions of transparency."
Personally, I feel these two concerns can be discussed together. It is dangerous for products to regard themselves as the “best” choice. I prefer that they are providing more options for users. I believe that users should have rights to make decisions for themselves, in the context of transparency. Transparency does not mean exposing the codings or algorithms, which is not understandable for most users. However, they can tell users what kind of data are being tracked and used (e.g. heart rate, medicines, text etc.), what results are generated based on those data. Meanwhile, users could have choices to stop tracking or using certain kinds of personal data. And they should be informed of the possible effects of doing so, such as a suboptimal treatment. They have the right to make their own choices and the responsibility to bear the consequences of their choices
##### "It would be a struggle—perhaps impossible—to develop a categorization schema that did not offend anyone."
I do not think it is possible to develop a categorization schema that did not offend anyone. Because one categorization means a specific extraction of a complicated subject. So it is always one-sided. And different understandings of the subject will result in different categorizations. Thus, I would prefer stop categorization, and find an alternative method. The purpose of categorization is to have a quick knowledge of the subject, what it is, what its characteristics. So, in order to achieve this purpose, is it possible to use matching rate instead of categorization? Which sound data does the input sound match most? In this way, both people and the AI still could have a quick knowledge of the subject while it is not subject to the subjective judgment of human.
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
# PROJECTS
<br>
<br>
<br>
<br>
<br>
### 01 Rube Goldberg Machine
![2901618924461_ pic_hd](https://user-images.githubusercontent.com/77864885/115404083-d6c56780-a1a1-11eb-908e-7d99f57596bf.jpg)

![3031618925403_ pic_hd](https://user-images.githubusercontent.com/77864885/115404365-1e4bf380-a1a2-11eb-8d7f-4c128d9a8b0e.jpg)

![3021618925402_ pic_hd](https://user-images.githubusercontent.com/77864885/115404323-1429f500-a1a2-11eb-8e99-640e00b86b7e.jpg)
<br>
<br>
<br>
<br>
<br>
### 02 Rate My Setup
![3061618934670_ pic_hd](https://user-images.githubusercontent.com/77864885/115428627-6e818080-a1b7-11eb-928f-9ac4574f5469.jpg)
<br>
<br>
<br>
<br>
<br>
### 03 Making Space
![2931618924973_ pic_hd](https://user-images.githubusercontent.com/77864885/115404563-4cc9ce80-a1a2-11eb-9ee4-7c31ad91d0b4.jpg)

![2941618924986_ pic_hd](https://user-images.githubusercontent.com/77864885/115404596-54897300-a1a2-11eb-8fd1-cc46afcc444a.jpg)

![2951618924991_ pic_hd](https://user-images.githubusercontent.com/77864885/115404623-5ce1ae00-a1a2-11eb-8492-3f9c41518637.jpg)
<br>
<br>
<br>
<br>
<br>
### 04 Raining Garden
![2971618925190_ pic_hd](https://user-images.githubusercontent.com/77864885/115404732-75ea5f00-a1a2-11eb-9779-3dc6954d2153.jpg)

![2981618925192_ pic_hd](https://user-images.githubusercontent.com/77864885/115404757-7b47a980-a1a2-11eb-861a-72f078a3875d.jpg)

![2991618925194_ pic_hd](https://user-images.githubusercontent.com/77864885/115404786-80a4f400-a1a2-11eb-90be-8fc7a138ff53.jpg)
<br>
<br>
<br>
<br>
<br>


